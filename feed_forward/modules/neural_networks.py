######### IMPORTS ##########
import torch,math
from torch import nn
import matplotlib.pyplot as plt
###########################

############################ AUXILIARY FUNCTIONS ##############################
def show_layers(model):
    print("\nLayers and parameters:\n")
    for name, param in model.named_parameters():
        print(f"Layer: {name} | Size: {param.size()} | Values : {param[:100]} \n")
        
def count_params(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)
    

############################## NEURAL NETWORKS ################################
class q_phi_layers(nn.Module):
    def __init__(self,Nin,Nhid,Nout,num_layers=1):
        super(q_phi_layers,self).__init__()
        
        self.actfun = nn.Sigmoid()
        
        layers_mu,layers_sigma = nn.ModuleList(),nn.ModuleList()
        layers_mu.append(nn.Linear(Nin,Nhid))
        layers_sigma.append(nn.Linear(Nin,Nhid))
        for _ in range(num_layers - 1):
            layers_mu.append(nn.Linear(Nhid,Nhid))
            layers_mu.append(self.actfun)
            layers_sigma.append(nn.Linear(Nhid,Nhid))
            layers_sigma.append(self.actfun)
        layers_mu.append(nn.Linear(Nhid,Nout))
        layers_sigma.append(nn.Linear(Nhid,Nout))
        self.layers_mu = layers_mu
        self.layers_sigma = layers_sigma
        self.softplus = nn.Softplus()
        self.N = Nin
        
        
    def prod_of_gaussians(self,x,params1,params2):
        global params_mu,params_sigma
        """
        Computes a pdf that is a product of gaussians given the means and stdevs.
        
        Parameters
        ----------
        x : TYPE
            DESCRIPTION.
        params : TYPE
            DESCRIPTION.

        Returns
        -------
        tensor
            Logarithm of q_phi.

        """

        params_mu = params1
        params_sigma = self.softplus(params2)
        sum_ = 0.5*(((x-params_mu)/params_sigma)**2)+torch.log(params_sigma)
        return -(torch.sum(sum_,dim=1)+self.N/2*torch.log(torch.tensor(2*math.pi)).repeat(x.size()[0]))
    
        
    def forward(self,x):
        o1 = nn.Sequential(*self.layers_mu)(x)
        o2 = nn.Sequential(*self.layers_sigma)(x)
        o = self.prod_of_gaussians(x,o1,o2)
        return o.squeeze(),params_mu,params_sigma
    

class q_phi_rnn(nn.Module):
    """
    Variational Feynman Path Generator
    
    Parameters
    ----------
    N : int
        length of the sequence
    input_size : int
        dimension of each vector of the input sequence (2D in the paper)
    hidden_size : int
        length of the output vector of the LSTM, h
    num_layers : int, optional
        number of stacked LSTM layers. The default is 1.
    Dense : bool, optional
        If true, adds a Linear layer that processes the output vector of 
        the LSTM and it returns the GMM parameters. The default is False.
    
    Returns
    -------
    x : list
        path generated by the VFPG by sampling from q.
    q_params : dict
        parameters of GMM at each time step.
    
    """
    def __init__(self,N,input_size,hidden_size,num_layers=1,Dense=False):
        super(q_phi_rnn, self).__init__()
        
        self.N = N
        self.input_size = input_size
        self.Dense_bool = Dense
        
        # Layers    
        self.lstm = nn.LSTM(input_size=input_size,hidden_size=hidden_size,num_layers=num_layers)
        if self.Dense_bool:
            self.Dense = nn.Linear(in_features=hidden_size,out_features=hidden_size)
        self.softmax = nn.Softmax(dim=0)
        self.softplus = nn.Softplus()
        
    def forward(self,x):
        lstm_out, _ = self.lstm(x)

            
        return lstm_out
    
    
    
    
    
    
    
    
    